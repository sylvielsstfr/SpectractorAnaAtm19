{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the photometry of the companion star\n",
    "\n",
    "- author : Sylvie Dagoret\n",
    "- date June 17 2019\n",
    "\n",
    "Use Photutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'photutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-068e1f4fcd71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigma_clipped_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mphotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCircularAperture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSqrtStretch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl_normalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageNormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mphotutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDAOStarFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'photutils'"
     ]
    }
   ],
   "source": [
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils import CircularAperture\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from photutils import DAOStarFinder\n",
    "from photutils import make_source_mask\n",
    "from astropy.stats import SigmaClip\n",
    "from photutils import Background2D, MedianBackground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "print('workbookDir: ' + workbookDir)\n",
    "\n",
    "spectractordir=workbookDir+\"/../../Spectractor\"\n",
    "print('spectractordir: ' + spectractordir)\n",
    "toolsdir=workbookDir+\"/../common_tools\"\n",
    "print(\"toolsdir:\",toolsdir)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(workbookDir)\n",
    "sys.path.append(spectractordir)\n",
    "sys.path.append(os.path.dirname(workbookDir))\n",
    "sys.path.append(toolsdir)\n",
    "\n",
    "\n",
    "\n",
    "from spectractor import parameters\n",
    "from spectractor.extractor.extractor import Spectractor\n",
    "from spectractor.logbook import LogBook\n",
    "from spectractor.extractor.dispersers import *\n",
    "from spectractor.extractor.spectrum import *\n",
    "from spectractor.tools import ensure_dir\n",
    "\n",
    "from libatmscattering import *\n",
    "\n",
    "\n",
    "plt.rcParams[\"axes.labelsize\"]=\"large\"\n",
    "plt.rcParams[\"axes.linewidth\"]=2.0\n",
    "plt.rcParams[\"xtick.major.size\"]=8\n",
    "plt.rcParams[\"ytick.major.size\"]=8\n",
    "plt.rcParams[\"ytick.minor.size\"]=5\n",
    "plt.rcParams[\"xtick.labelsize\"]=\"large\"\n",
    "plt.rcParams[\"ytick.labelsize\"]=\"large\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=(15,15)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "#plt.rcParams['axes.facecolor'] = 'blue'\n",
    "plt.rcParams['xtick.direction'] = 'out'\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['lines.markeredgewidth'] = 0.3 # the line width around the marker symbol\n",
    "plt.rcParams['lines.markersize'] = 5  # markersize, in points\n",
    "plt.rcParams['grid.alpha'] = 0.75 # transparency, between 0.0 and 1.0\n",
    "plt.rcParams['grid.linestyle'] = '-' # simple line\n",
    "plt.rcParams['grid.linewidth'] = 0.4 # in points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CONFIGURATION\n",
    "\n",
    "## wavelength\n",
    "WLMIN = 380.0\n",
    "WLMAX = 1000.0\n",
    "#NBWLBIN = 62\n",
    "NBWLBIN = 124\n",
    "WLBINWIDTH = (WLMAX - WLMIN) / float(NBWLBIN)\n",
    "\n",
    "WLMINBIN = np.arange(WLMIN, WLMAX, WLBINWIDTH)\n",
    "WLMAXBIN = np.arange(WLMIN + WLBINWIDTH, WLMAX + WLBINWIDTH, WLBINWIDTH)\n",
    "WLMEANBIN=(WLMINBIN + WLMAXBIN)/2.\n",
    "\n",
    "\n",
    "\n",
    "print('WLMINBIN..................................=', WLMINBIN.shape, WLMINBIN)\n",
    "print('WLMAXBIN..................................=', WLMAXBIN.shape, WLMAXBIN)\n",
    "print('NBWLBIN...................................=', NBWLBIN)\n",
    "print('WLBINWIDTH................................=', WLBINWIDTH)\n",
    "\n",
    "## colors\n",
    "\n",
    "# wavelength bin colors\n",
    "jet = plt.get_cmap('jet')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=NBWLBIN)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "all_colors = scalarMap.to_rgba(np.arange(NBWLBIN), alpha=1)\n",
    "\n",
    "## output directory for tables\n",
    "#ouputtabledir=\"outputtabledir\"\n",
    "\n",
    "## create output directory\n",
    "#ensure_dir(ouputtabledir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def GetWLBin(wl):\n",
    "    \"\"\"\n",
    "\n",
    "    :param wl: wavelength scalar\n",
    "    :return: index\n",
    "    \"\"\"\n",
    "\n",
    "    set_ibin = np.where(np.logical_and(WLMINBIN <= wl, WLMAXBIN > wl))[0]\n",
    "\n",
    "    if len(set_ibin)==1:\n",
    "        return set_ibin[0]\n",
    "    else:\n",
    "        return -1\n",
    "#---------------------------------------------------------------------\n",
    "def GETWLLabels():\n",
    "\n",
    "    all_labels=[]\n",
    "    for idx in np.arange(NBWLBIN):\n",
    "        label=\"$\\lambda$ : {:3.0f}-{:3.0f} nm\".format(WLMINBIN[idx], WLMAXBIN[idx])\n",
    "        all_labels.append(label)\n",
    "    all_labels=np.array(all_labels)\n",
    "    return all_labels\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "WLLABELS=GETWLLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \n",
    "    For example for the PSF\n",
    "    \n",
    "    x=pixel number\n",
    "    y=Intensity in pixel\n",
    "    \n",
    "    values-x\n",
    "    weights=y=f(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    variance = np.average((values - average) ** 2, weights=weights)  # Fast and numerically precise\n",
    "    return average, np.sqrt(variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeStarPhotometry(image):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    mask = make_source_mask(image, snr=3, npixels=5, dilate_size=11)\n",
    "    mean, median, std = sigma_clipped_stats(image, sigma=3.0, mask=mask)\n",
    "    sigma_clip = SigmaClip(sigma=3.)\n",
    "    bkg_estimator = MedianBackground()\n",
    "    bkg = Background2D(image, (50, 50), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)\n",
    "    signal = image - bkg.background\n",
    "    mean, median, std = sigma_clipped_stats(signal, sigma=3.0)\n",
    "    daofind = DAOStarFinder(fwhm=10.0, threshold=100. * std)\n",
    "    sources = daofind(signal - median)\n",
    "    for col in sources.colnames:\n",
    "        sources[col].info.format = '%.8g'  # for consistent table output\n",
    "    print(sources)\n",
    "\n",
    "    #select the source having ymin\n",
    "    allY=sources[\"ycentroid\"]\n",
    "    idx=np.where(allY==allY.min())[0][0]\n",
    "    flux=sources[\"flux\"][idx]\n",
    "    mag=sources[\"mag\"][idx]\n",
    "    \n",
    "    print(\" idx={}\".format(idx))\n",
    "    \n",
    "    return flux,mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are the spectra\n",
    "#----------------------\n",
    "thedate = \"20190215\"\n",
    "#input_directory = \"/Users/dagoret/DATA/PicDuMidiFev2019/spectractor_output_prod3/\" + thedate\n",
    "input_directory = \"/Users/dagoret/DATA/PicDuMidiFev2019/spectractor_output_prod4/\" + thedate\n",
    "rawinput_directory=\"/Users/dagoret/DATA/PicDuMidiFev2019/prod_\"+thedate+\"_v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "def GetAllFiles(dir):\n",
    "    \"\"\"\n",
    "    GetAllFiles(dir): provides the list of relevant files inside the directory dir\n",
    "\n",
    "\n",
    "    :param dir: input directory pathname\n",
    "    :return: list of files\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # get all files\n",
    "    onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "    onlyfiles = np.array(onlyfiles)\n",
    "\n",
    "    # sort files\n",
    "    sortedindexes = np.argsort(onlyfiles)\n",
    "    onlyfiles = onlyfiles[sortedindexes]\n",
    "\n",
    "    # get only _spectrum.fits file\n",
    "    onlyfilesspectrum = []\n",
    "    for file_name in onlyfiles:\n",
    "        if re.search(\"^T.*_spectrum.fits$\", file_name):\n",
    "            # check if other files exits\n",
    "\n",
    "            filetype = file_name.split('.')[-1]\n",
    "\n",
    "            output_filename = os.path.basename(file_name)\n",
    "            output_filename = os.path.join(dir, output_filename)\n",
    "            output_filename_spectrogram = output_filename.replace('spectrum', 'spectrogram')\n",
    "            output_filename_psf = output_filename.replace('spectrum.fits', 'table.csv')\n",
    "\n",
    "            # go to next simulation if output files already exists\n",
    "            if os.path.isfile(output_filename) and os.path.isfile(output_filename_spectrogram) and os.path.isfile(\n",
    "                    output_filename_psf):\n",
    "                filesize = os.stat(output_filename).st_size\n",
    "                print(\">>>>> output filename : {} already exists with size {} \".format(output_filename, filesize))\n",
    "\n",
    "                filesize = os.stat(output_filename_spectrogram).st_size\n",
    "                print(\">>>>> output filename : {} already exists with size {} \".format(output_filename_spectrogram,\n",
    "                                                                                       filesize))\n",
    "\n",
    "                filesize = os.stat(output_filename_psf).st_size\n",
    "                print(\">>>>> output filename : {} already exists with size {} \".format(output_filename_psf, filesize))\n",
    "\n",
    "                onlyfilesspectrum.append(re.findall(\"(^T.*_spectrum.fits$)\", file_name)[0])\n",
    "\n",
    "    # sort again all the files\n",
    "    onlyfilesspectrum = np.array(onlyfilesspectrum)\n",
    "    sortedindexes = np.argsort(onlyfilesspectrum)\n",
    "    onlyfilesspectrum = onlyfilesspectrum[sortedindexes]\n",
    "\n",
    "    # get basnemae of files for later use (to check if _table.csv and _spectrogram.fits exists\n",
    "    onlyfilesbasename = []\n",
    "    for f in onlyfilesspectrum:\n",
    "        onlyfilesbasename.append(re.findall(\"(^T.*)_spectrum.fits$\", f)[0])\n",
    "\n",
    "\n",
    "    return onlyfilesspectrum,onlyfilesbasename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAllFiles(dir, filelist):\n",
    "    \"\"\"\n",
    "\n",
    "    ReadAllFiles(dir, filelist): Read all files\n",
    "\n",
    "    :param dir: input directory\n",
    "    :param filelist: list fo files\n",
    "    :return: various containers\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # init all container\n",
    "    all_indexes=[]   # continuous index\n",
    "    all_eventnum=[]  # event number on filename\n",
    "\n",
    "    all_airmass=[]   #airmass\n",
    "\n",
    "    all_lambdas = [] # wavelength\n",
    "\n",
    "    #fluxes\n",
    "    all_flux=[]\n",
    "    all_errflux=[]\n",
    "\n",
    "\n",
    "    # magnitudes\n",
    "    all_mag=[]\n",
    "    all_errmag=[]\n",
    "\n",
    "    # absorption (Magnitude corrected from Rayleigh\n",
    "    all_abs=[]\n",
    "    all_errabs=[]\n",
    "\n",
    "\n",
    "    all_dt       = []   # time since beginning in hours\n",
    "    all_datetime = []   # datetime\n",
    "\n",
    "    # preselection flag\n",
    "    all_flag = []\n",
    "\n",
    "\n",
    "    #bad indexes and filename\n",
    "    all_badidx=[]\n",
    "    all_badfn=[]\n",
    "\n",
    "\n",
    "    all_BGimg=[]\n",
    "    all_Rawimg=[]\n",
    "\n",
    "    NBSPEC = len(filelist)\n",
    "\n",
    "\n",
    "    #----------------------------------\n",
    "    # Extract spectra information from files\n",
    "    # compute magnitudes\n",
    "    #-----------------------------\n",
    "\n",
    "    count=-1  #counter of good files before filtering\n",
    "\n",
    "    # loop on all files\n",
    "    for idx in np.arange(0, NBSPEC):\n",
    "        if idx==322:\n",
    "            print(\"SKIP bad file\",filelist[idx] )\n",
    "            continue\n",
    "\n",
    "        count+=1\n",
    "\n",
    "        theeventnum = int(filelist[idx].split(\".\")[1].split(\"_\")[0])\n",
    "\n",
    "\n",
    "        print(\" read {}) : event {} , file {}\".format(idx,theeventnum,filelist[idx]))\n",
    "\n",
    "\n",
    "        fullfilename = os.path.join(dir, filelist[idx])\n",
    "        fullfilename_spectrogram = fullfilename.replace('spectrum', 'spectrogram')\n",
    "        rawfilename = filelist[idx].replace('_spectrum.fits', '.fit')\n",
    "        fillrawfilename=os.path.join(rawinput_directory,rawfilename)\n",
    "        \n",
    "\n",
    "        #try:\n",
    "        if 1:\n",
    "            # read fits file\n",
    "            hdu = fits.open(fullfilename)\n",
    "            hdu2=fits.open(fullfilename_spectrogram)\n",
    "            hdu3=fits.open(fillrawfilename)\n",
    "\n",
    "            \n",
    "\n",
    "            # decode header\n",
    "            header=hdu[0].header\n",
    "\n",
    "            am=header[\"AIRMASS\"]\n",
    "            date=header[\"DATE-OBS\"]\n",
    "\n",
    "            if idx==0:\n",
    "                T0=t = Time(date, format='isot', scale='utc')\n",
    "            T=Time(date, format='isot', scale='utc')\n",
    "            thedatetime=T.to_datetime()\n",
    "\n",
    "            DT=(T-T0).sec/(3600.0)  # convert in hours\n",
    "\n",
    "\n",
    "            # decode data\n",
    "            data=hdu[0].data\n",
    "\n",
    "            # extract wavelength, spectrum and errors\n",
    "            wavelength=data[0,:]\n",
    "            spec = data[1,:]\n",
    "            err=data[2,: ]\n",
    "\n",
    "            if(len(wavelength)==0 or len(spec)==0 or len(err)==0):\n",
    "                print(\">>>>>>>>>>>>>>  Empty file \",idx,\")::\",onlyfilesspectrum[idx] )\n",
    "                print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>\",len(wavelength),\" , \",len(spec0), \" , \",len(err))\n",
    "\n",
    "\n",
    "\n",
    "            # sort the wavelengths\n",
    "            wl_sorted_idx=np.argsort(wavelength)\n",
    "\n",
    "            wl=wavelength[wl_sorted_idx]\n",
    "            fl=spec[wl_sorted_idx]\n",
    "            errfl=err[wl_sorted_idx]\n",
    "            wlbins = [GetWLBin(w) for w in wl]\n",
    "            wlbins = np.array(wlbins)\n",
    "\n",
    "\n",
    "            # defines good measurmements as flux >0 and wavelength in selected bons\n",
    "            goodpoints=np.where(np.logical_and(fl != 0, wlbins != -1))\n",
    "\n",
    "            if(len(goodpoints)==0):\n",
    "                print(\">>>>>>>>>>>>>>  No Good points  \", idx, \")::\", onlyfilesspectrum[idx])\n",
    "                print(\">>>>>>>>>>>>>>  No Good points  \", \"wl = \",wl)\n",
    "                print(\">>>>>>>>>>>>>>  No Good points  \", \"fl = \", fl)\n",
    "                print(\">>>>>>>>>>>>>>  No Good points  \", \"errfl = \", errfl)\n",
    "\n",
    "\n",
    "\n",
    "            # keep good points (wl,flux)\n",
    "            wl=wl[goodpoints]\n",
    "            fl=fl[goodpoints]\n",
    "            errfl=errfl[goodpoints]\n",
    "\n",
    "\n",
    "            # convert flux into magnitudes for each wavelength\n",
    "            mag = -2.5 * np.log10(fl)\n",
    "            errmag = errfl/fl\n",
    "\n",
    "            #compute effective slant Rayleigh optical depth (not the vertical optical depth)\n",
    "            od_adiab = RayOptDepth_adiabatic(wl,altitude=2890.5, costh=1./am)  # Rayleigh optical depth\n",
    "\n",
    "            # absorption magnitude corrected from Rayleigh attenuation\n",
    "            abs=mag-2.5/np.log(10.)*od_adiab\n",
    "            errabs=errmag\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # save for each observation  { event-id, airmass, set of points (wl,flux,errflux, mag,abs,errabs) }\n",
    "            if(len(mag>0)):\n",
    "                #all_indexes.append(idx)\n",
    "                all_indexes.append(count)\n",
    "                all_eventnum.append(theeventnum)\n",
    "                all_airmass.append(am)\n",
    "                all_lambdas.append(wl)\n",
    "                all_flux.append(fl)\n",
    "                all_errflux.append(errfl)\n",
    "                all_mag.append(mag)\n",
    "                all_errmag.append(errmag)\n",
    "                all_abs.append(abs)\n",
    "                all_errabs.append(errabs)\n",
    "                all_dt.append(DT)\n",
    "                all_datetime.append(thedatetime)\n",
    "                all_BGimg.append(hdu2[2].data)\n",
    "                all_Rawimg.append(hdu3[0].data)\n",
    "\n",
    "                absmin = abs.min()\n",
    "                absmax = abs.max()\n",
    "\n",
    "\n",
    "                # Set a quality flag\n",
    "                if absmin < 25 or absmax > 32:\n",
    "                    print(\"file index idx = \", count, \"==>  filename = \", onlyfilesspectrum[idx], \" absmin= \", absmin,\n",
    "                          \" absmax = \", absmax)\n",
    "                    all_flag.append(False)\n",
    "                    all_badidx.append(count)\n",
    "                    all_badfn.append(onlyfilesspectrum[idx])\n",
    "                else:\n",
    "                    all_flag.append(True)\n",
    "\n",
    "\n",
    "\n",
    "        #except:\n",
    "        if 0:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            pass\n",
    "\n",
    "    # transform container in numpy arrays\n",
    "    all_indexes=np.array(all_indexes)\n",
    "    all_eventnum = np.array(all_eventnum)\n",
    "\n",
    "    all_airmass = np.array(all_airmass)\n",
    "\n",
    "    all_lambdas = np.array(all_lambdas)\n",
    "\n",
    "    all_flux = np.array(all_flux)\n",
    "    all_errflux = np.array(all_errflux)\n",
    "\n",
    "\n",
    "    all_mag=np.array(all_mag)\n",
    "    all_errmag=np.array(all_errmag)\n",
    "\n",
    "    all_abs = np.array(all_abs)\n",
    "    all_errabs = np.array(all_errabs)\n",
    "\n",
    "    all_dt = np.array(all_dt)\n",
    "    all_datetime=np.array(all_datetime)\n",
    "\n",
    "    all_flag = np.array(all_flag)\n",
    "\n",
    "    all_badidx=np.array(all_badidx)\n",
    "    all_badfn=np.array(all_badfn)\n",
    "\n",
    "\n",
    "    return all_indexes,all_eventnum,all_airmass,all_lambdas,all_flux,all_errflux,all_mag,all_errmag,all_abs,all_errabs,all_dt,all_datetime,all_flag,all_badidx,all_badfn, all_BGimg, all_Rawimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 1) Get list of files\n",
    "##########################################\n",
    "onlyfilesspectrum,onlyfilesbasename=GetAllFiles(input_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2) Read fits file\n",
    "##########################################\n",
    "\n",
    "\n",
    "NBSPEC = len(onlyfilesspectrum)\n",
    "\n",
    "print('NBSPEC....................................= ', NBSPEC)\n",
    "\n",
    "\n",
    "all_indexes, all_eventnum, all_airmass, all_lambdas, all_flux, all_errflux, all_mag, all_errmag, all_abs, all_errabs, all_dt, all_datetime, all_flag, all_badidx, all_badfn, all_BGimg, all_Rawimg=ReadAllFiles(input_directory, onlyfilesspectrum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBSPEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mag=[]\n",
    "all_flux=[]\n",
    "\n",
    "idx=0\n",
    "for img in all_Rawimg:\n",
    "    print(\"************************************** {} ***************************************\".format(idx))\n",
    "    flux,mag=ComputeStarPhotometry(img)\n",
    "\n",
    "    all_mag.append(mag)\n",
    "    all_flux.append(flux)\n",
    "    idx+=1\n",
    "    \n",
    "    if idx>50:\n",
    "        break\n",
    "\n",
    "all_mag=np.array(all_mag)\n",
    "all_flux=np.array(all_flux)\n",
    "\n",
    "\n",
    "print(all_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study a particular image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=32 # exemple de boug√©\n",
    "#index=0 # image OK\n",
    "image=all_Rawimg[index]\n",
    "vmin=image.min()\n",
    "vmax=image.max()/50.\n",
    "thefilename=onlyfilesspectrum[index] #onlyfilesbasename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img=plt.imshow(data,origin=\"lower\",vmin=vmin,vmax=vmax,cmap=\"jet\")\n",
    "plt.grid(color=\"w\")\n",
    "plt.title(thefilename)\n",
    "plt.xlabel(\" X - pixel \")\n",
    "plt.ylabel(\" Y - pixel \")\n",
    "plt.colorbar(img,orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "XMIN=10\n",
    "XMAX=1000\n",
    "plt.hist(data.flatten(), bins = 10 ** np.linspace(np.log10(XMIN), np.log10(XMAX), 100),color=\"b\",alpha=0.8)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "#plt.gca().set_yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.title(\"Reduced image ADU counts for {}\".format(thefilename))\n",
    "plt.xlabel(\"ADU counts\")\n",
    "plt.ylabel(\"number of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, median, std = sigma_clipped_stats(data, sigma=3.0)    \n",
    "print((mean, median, std))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Sources in raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daofind = DAOStarFinder(fwhm=10.0, threshold=100.*std)    \n",
    "sources = daofind(data - median) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sources.colnames:    \n",
    "    sources[col].info.format = '%.8g'  # for consistent table output\n",
    "print(sources)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=50.)\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "#plt.imshow(data,cmap='Greys', origin='lower', norm=norm)\n",
    "img=plt.imshow(data,cmap='jet', origin='lower', norm=norm,vmin=vmin,vmax=vmax)\n",
    "apertures.plot(color='red', lw=3, alpha=1.0)\n",
    "\n",
    "plt.grid(color=\"w\")\n",
    "plt.title(thefilename)\n",
    "plt.colorbar(img,orientation=\"horizontal\")\n",
    "plt.xlabel(\" X - pixel \")\n",
    "plt.ylabel(\" Y - pixel \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = make_source_mask(data, snr=3, npixels=5, dilate_size=11)\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=3.0, mask=mask)\n",
    "print((mean, median, std))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_clip = SigmaClip(sigma=3.)\n",
    "bkg_estimator = MedianBackground()\n",
    "bkg = Background2D(data, (50, 50), filter_size=(3, 3),sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=plt.imshow(bkg.background, origin='lower', cmap='Greys_r')\n",
    "img=plt.imshow(bkg.background, origin='lower', cmap='jet')\n",
    "plt.grid(color=\"w\")\n",
    "plt.title(\"Background for {}\".format(thefilename))\n",
    "plt.xlabel(\" X - pixel \")\n",
    "plt.ylabel(\" Y - pixel \")\n",
    "plt.colorbar(img,orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "XMIN=10\n",
    "XMAX=1000\n",
    "plt.hist(bkg.background.flatten(), bins = 10 ** np.linspace(np.log10(XMIN), np.log10(XMAX), 100),color=\"b\",alpha=0.8)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "#plt.gca().set_yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.title(\"Background ADU counts for {}\".format(thefilename))\n",
    "plt.xlabel(\"ADU counts\")\n",
    "plt.ylabel(\"number of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "XMIN=20\n",
    "XMAX=100\n",
    "plt.hist(bkg.background.flatten(), bins = np.linspace(XMIN,XMAX, 100),color=\"b\",alpha=0.8)\n",
    "#plt.gca().set_xscale(\"log\")\n",
    "#plt.gca().set_yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.title(\"Background ADU counts for {}\".format(thefilename))\n",
    "plt.xlabel(\"ADU counts\")\n",
    "plt.ylabel(\"number of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal=data - bkg.background\n",
    "vmin=signal.min()\n",
    "vmax=signal.max()/50.\n",
    "#plt.imshow(signal, norm=norm, origin='lower',cmap='Greys_r',vmin=vmin,vmax=vmax)\n",
    "img=plt.imshow(signal, norm=norm, origin='lower',cmap='jet',vmin=vmin,vmax=vmax)\n",
    "plt.colorbar(img,orientation=\"horizontal\")\n",
    "plt.title(\"Signal for {}\".format(thefilename))\n",
    "plt.xlabel(\" X - pixel \")\n",
    "plt.ylabel(\" Y - pixel \")\n",
    "plt.grid(color=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, median, std = sigma_clipped_stats(signal, sigma=3.0)    \n",
    "print((mean, median, std))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daofind = DAOStarFinder(fwhm=10.0, threshold=100.*std)    \n",
    "sources = daofind(data - median) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sources.colnames:    \n",
    "    sources[col].info.format = '%.8g'  # for consistent table output\n",
    "print(sources)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=50.)\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "#plt.imshow(data,cmap='Greys', origin='lower', norm=norm)\n",
    "img=plt.imshow(signal,cmap='jet', origin='lower', norm=norm,vmin=vmin,vmax=vmax)\n",
    "apertures.plot(color='red', lw=3, alpha=1.0)\n",
    "plt.grid(color=\"w\")\n",
    "plt.title(\"Signal for {}\".format(thefilename))\n",
    "plt.colorbar(img,orientation=\"horizontal\")\n",
    "plt.xlabel(\" X - pixel \")\n",
    "plt.ylabel(\" Y - pixel \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "XMIN=0.01\n",
    "XMAX=10000\n",
    "plt.hist(signal.flatten(), bins = 10 ** np.linspace(np.log10(XMIN), np.log10(XMAX), 100),color=\"b\",alpha=0.8)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "#plt.gca().set_yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.title(\"Signal ADU counts for {}\".format(thefilename))\n",
    "plt.xlabel(\"ADU counts\")\n",
    "plt.ylabel(\"number of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=sources[\"xcentroid\"][0]\n",
    "y0=sources[\"ycentroid\"][0]\n",
    "siz=20\n",
    "pixel_to_arcsec=0.159\n",
    "extent=(-siz*pixel_to_arcsec,siz*pixel_to_arcsec, -siz*pixel_to_arcsec,siz*pixel_to_arcsec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vignette=signal[int(y0-siz):int(y0+siz),int(x0-siz):int(x0+siz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "XMIN=10\n",
    "XMAX=100000\n",
    "plt.hist(vignette.flatten(), bins = 10 ** np.linspace(np.log10(XMIN), np.log10(XMAX), 100),color=\"b\",alpha=0.8)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "#plt.gca().set_yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.title(\"Star ADU counts for {}\".format(thefilename))\n",
    "plt.xlabel(\"ADU counts\")\n",
    "plt.ylabel(\"number of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imshow(vignette,origin=\"lower\",cmap=\"jet\",extent=extent)\n",
    "plt.colorbar(img,orientation=\"horizontal\")\n",
    "plt.xlabel(\"$\\\\theta_X$ (arcsec)\")\n",
    "plt.ylabel(\"$\\\\theta_Y$ (arcsec)\")\n",
    "plt.title(thefilename)\n",
    "plt.grid(color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histx=vignette.sum(axis=0)\n",
    "histy=vignette.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx=len(histx)\n",
    "ly=len(histy)\n",
    "mx,sx=weighted_avg_and_std(np.arange(lx),histx)\n",
    "my,sy=weighted_avg_and_std(np.arange(ly),histy)\n",
    "hxmin,hxmax=histx.min(),histx.max()\n",
    "hymin,hymax=histy.min(),histy.max()\n",
    "hxaver=(hxmin+hxmax)/2.\n",
    "hyaver=(hymin+hymax)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx,sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.plot(histx,'b-o')\n",
    "plt.plot([mx,mx],[hxmin,hxmax],\"r-\")\n",
    "plt.plot([(lx+1.)/2.-2.36/2.*sx, (lx+1)/2.+2.36/2.*sx],[hxaver,hxaver],\"g-\")\n",
    "plt.xlabel(\"x - pixel\")\n",
    "plt.title(\"$\\sigma_x$= {:1.2f} pix = {:1.2f} arcsec\".format(sx,sx*pixel_to_arcsec))\n",
    "plt.grid()\n",
    "plt.subplot(222)\n",
    "plt.plot(histy,'b-o')\n",
    "plt.plot([my,my],[hymin,hymax],\"r-\")\n",
    "plt.plot([(ly+1)/2.-2.36/2.*sy, (ly+1)/2.+2.36/2.*sy],[hyaver,hyaver],\"g-\")\n",
    "plt.xlabel(\"y - pixel\")\n",
    "plt.title(\"$\\sigma_y$= {:1.2f} pix = {:1.2f} arcsec\".format(sy,sy*pixel_to_arcsec))\n",
    "plt.grid()\n",
    "plt.suptitle(thefilename,fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
